services:
  vllm-qwen3:
    image: harbor.vastaitech.com/ai_deliver/vllm_vacc:AI3.0_SP5_0718
    privileged: true
    shm_size: '64gb'
    network_mode: host
    container_name: vllm_service
    restart: "on-failure:3"
    environment:
      - VACC_VISIBLE_DEVICES=0,1
    volumes:
      - ${QWEN3_30B_MODEL_PATH}:/weights/Qwen3-30B-A3B-FP8
    entrypoint: >
      sh -c "
      if dmesg | grep -q \"iommu is enable\"; then echo \"Error! IOMMU is enable, please close IOMMU first\"; sleep 10; exit 1; fi;
      unset VNNL_MODEL_SYNC VCCL_MODEL_SYNC LOG_TRAIN_SCHEDULE VACM_LOG_CFG VACC_RT_MODELSAVE_EN;
      for i in $$(seq 0 1); do if [ ! -e /dev/vacc$$i ]; then sleep 5; exit 1; fi; done;        
      vllm serve /weights/Qwen3-30B-A3B-FP8 --trust-remote-code --tensor-parallel-size 2 --max-model-len 65536 \
      --enforce-eager --rope-scaling '{\"rope_type\":\"yarn\",\"factor\":2.0,\"original_max_position_embeddings\":32768}' \
      --enable-reasoning --reasoning-parser deepseek_r1 --enable-auto-tool-choice --tool-call-parser hermes  --host 0.0.0.0 \
      --port 8000 --served-model-name Qwen3;
      "
